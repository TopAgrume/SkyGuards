services:

  #skyguards-service:
  #  build:
  #    context: ./skyguards
  #  depends_on:
  #    - kafka-broker-1
  #  environment:
  #    KAFKA_HOST: kafka-broker-1:9092
  #    REPORT_TOPIC: reports
  #    SCENARIO: 1
  #    NB_DRONE: 5
  #  deploy:
  #    replicas: 1
  #  command: ["sbt", "run"]

  #########
  # KAFKA #
  #########

  kafka-zookeeper-1:
    image: confluentinc/cp-zookeeper:7.6.1
    user: root
    restart: on-failure
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka-broker-1:
    image: confluentinc/cp-kafka:7.6.1
    restart: on-failure
    hostname: kafka-broker-1
    ports:
      - "29092:29092"
    depends_on:
      - kafka-zookeeper-1
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "kafka-zookeeper-1:2181"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker-1:9092,PLAINTEXT_INTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      TOPIC_AUTO_CREATE: false

  init-kafka-topic-1:
    image: confluentinc/cp-kafka:7.6.1
    volumes:
      - ./script:/script/
    environment:
      KAFKA_BROKER: "kafka-broker-1:9092"
    depends_on:
      - kafka-broker-1
    entrypoint: ["/bin/sh", "-c"]
    command: [ 'sh /script/setup-kafka.sh' ]

  #########
  # SPARK #
  #########

  # Made with the help of:
  # https://dev.to/mvillarrealb/creating-a-spark-standalone-cluster-with-docker-and-docker-compose-2021-update-6l4

  spark-master:
    user: root
    hostname: spark_master
    image: spark:3.5.1-scala2.12-java11-ubuntu
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      - SPARK_MODE=master
      - SPARK_LOCAL_IP=spark-master
    depends_on:
      - kafka-broker-1
    ports:
      - "9090:8080"
      - "7077:7077"

  spark-worker-a:
    image: spark:3.5.1-scala2.12-java11-ubuntu
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=256M
      - SPARK_DRIVER_MEMORY=256M
      - SPARK_EXECUTOR_MEMORY=256M
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-a
    depends_on:
      - spark-master
    ports:
      - "9991:8080"
      - "7000:7000"

  spark-worker-b:
    image: spark:3.5.1-scala2.12-java11-ubuntu
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=256M
      - SPARK_DRIVER_MEMORY=256M
      - SPARK_EXECUTOR_MEMORY=256M
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-b
    depends_on:
      - spark-master
    ports:
      - "9992:8080"
      - "7001:7000"

  #############
  # S3 Bucket #
  #############

  ##############
  # SLOW START #
  ##############

  kafka:
    image: tianon/true
    depends_on:
      - kafka-broker-1
      - init-kafka-topic-1
    restart: "no"

  #skyguards:
  #  image: tianon/true
  #  depends_on:
  #    - skyguards-service
  #  restart: "no"

  spark:
    image: tianon/true
    depends_on:
      - spark-master
      - spark-worker-a
      - spark-worker-b
  #    - spark-streaming
    restart: "no"
