services:

  skyguards-service:
    build:
      context: ./skyguards
    depends_on:
      - kafka-broker-1
    environment:
      PL_KAFKA_HOST: kafka-broker-1:9092
      PL_REPORT_TOPIC: reports
    deploy:
      replicas: 1

  #########
  # KAFKA #
  #########

  kafka-zookeeper-1:
    image: confluentinc/cp-zookeeper:7.6.1
    user: root
    restart: on-failure
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka-broker-1:
    image: confluentinc/cp-kafka:7.6.1
    restart: on-failure
    hostname: kafka-broker-1
    ports:
      - "9092:9092"
    expose:
      - "29092"
    depends_on:
      - kafka-zookeeper-1
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "kafka-zookeeper-1:2181"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka-broker-1:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      TOPIC_AUTO_CREATE: false

  init-kafka-topic-1:
    image: confluentinc/cp-kafka:7.6.1
    volumes:
      - ./script:/script/
    environment:
      KAFKA_BROKER: "kafka-broker-1:29092"
    depends_on:
      - kafka-broker-1
    entrypoint: ["/bin/sh", "-c"]
    command: [ 'sh /script/setup-kafka.sh' ]

  #########
  # SPARK #
  #########

  # Made with the help of:
  # https://dev.to/mvillarrealb/creating-a-spark-standalone-cluster-with-docker-and-docker-compose-2021-update-6l4

  spark-master:
    user: root
    hostname: spark_master
    build:
      context: ./spark-streaming
    environment:
      - SPARK_MODE=master
      - SPARK_LOCAL_IP=spark-master
      #- SPARK_RPC_AUTHENTICATION_ENABLED=no
      #- SPARK_RPC_ENCRYPTION_ENABLED=no
      #- SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      #- SPARK_SSL_ENABLED=no
    volumes:
       - ./spark/apps:/opt/spark-apps
       - ./spark/data:/opt/spark-data
    ports:
      - "9090:8080"
      - "7077:7077"

  spark-worker-a:
    build:
      context: ./spark-streaming
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-a
    depends_on:
      - spark-master
    ports:
      - "9991:8080"
      - "7000:7000"

  spark-worker-b:
    build:
      context: ./spark-streaming
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-b
    depends_on:
      - spark-master
    ports:
      - "9992:8080"
      - "7001:7000"

  #spark-streaming:
  #  build:
  #    context: ./spark-streaming
  #  depends_on:
  #    - kafka-broker-1
  #    - spark-master
  #    - spark-worker-1
  #    - spark-worker-2
  #  environment:
  #    - KAFKA_BOOTSTRAP_SERVERS=kafka-broker-1:9092

  #############
  # S3 Bucket #
  #############

  ##############
  # SLOW START #
  ##############

  kafka:
    image: tianon/true
    depends_on:
      - kafka-broker-1
      - init-kafka-topic-1
    restart: "no"

  skyguards:
    image: tianon/true
    depends_on:
      - skyguards-service
    restart: "no"

  spark:
    image: tianon/true
    depends_on:
      - spark-master
      - spark-worker-a
      - spark-worker-b
  #    - spark-streaming
    restart: "no"
